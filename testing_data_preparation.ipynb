{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omar-Abd-Elwahab/VCF_filter/blob/main/data_preparation2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvttGs13FkA1",
        "outputId": "cf574044-1069-4663-d4cc-d1b45f99b723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libhts3 libhtscodecs2 python3-pysam python3-vcf\n",
            "The following NEW packages will be installed:\n",
            "  libhts3 libhtscodecs2 python3-pysam python3-vcf pyvcf\n",
            "0 upgraded, 5 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 2,243 kB of archives.\n",
            "After this operation, 7,117 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhtscodecs2 amd64 1.1.1-3 [53.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhts3 amd64 1.13+ds-2build1 [390 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pysam amd64 0.17.0+ds-2build1 [1,749 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-vcf amd64 0.6.8+git20170215.476169c-8build1 [43.5 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pyvcf all 0.6.8+git20170215.476169c-8build1 [7,760 B]\n",
            "Fetched 2,243 kB in 0s (5,055 kB/s)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install pyvcf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDG3wFEmGbUH"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y tabix\n",
        "!pip install pytabix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wifOrgKIFMO8"
      },
      "outputs": [],
      "source": [
        "# Opening the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rig8kQ5EFYqK"
      },
      "outputs": [],
      "source": [
        "cd ./drive/MyDrive/Colab\\ Notebooks/deepref\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkvNf6JfC8Jb"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K3u9x5d8SXy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!grep -o -i PASS HG003_GRCh38_1_22_v4.2.1_benchmark.vcf | wc -l\n",
        "!grep -o -i FAIL HG003_GRCh38_1_22_v4.2.1_benchmark.vcf | wc -l"
      ],
      "metadata": {
        "id": "N5OXup-rWZzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKxXK6wW7WHm"
      },
      "outputs": [],
      "source": [
        "import vcf\n",
        "\n",
        "#if a variat exist in both a VCF file anf the reference VCF, the variant FILTER is set to PASS. Else, it is FAIL\n",
        "def update_filter_column(vcf_file, reference_vcf, output_vcf):\n",
        "    vcf_reader = vcf.Reader(filename=vcf_file)\n",
        "    reference_reader = vcf.Reader(filename=reference_vcf)\n",
        "\n",
        "    reference_variants = set((record.POS) for record in reference_reader)\n",
        "\n",
        "    vcf_writer = vcf.Writer(open(output_vcf, 'w'), vcf_reader)\n",
        "\n",
        "    for record in vcf_reader:\n",
        "        variant_key = (record.POS)\n",
        "        if variant_key in reference_variants:\n",
        "            record.FILTER = \"PASS\"\n",
        "\n",
        "        else:\n",
        "            record.FILTER = \"FAIL\"\n",
        "\n",
        "        vcf_writer.write_record(record)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtGdqJyO7Rho"
      },
      "outputs": [],
      "source": [
        "# Provide the paths to your VCF files\n",
        "#file_1 = \"HG003_platypus.vcf\"\n",
        "file_2 = \"HG003-bcf.vcf\"\n",
        "file_4 = \"HG003_gatk.vcf\"\n",
        "reference_vcf_path = \"HG003_GRCh38_1_22_v4.2.1_benchmark.vcf\"\n",
        "#output_1 = \"/content/HG003_platypus_updated.vcf\"\n",
        "output_2 = \"/content/HG003_bcf_updated.vcf\"\n",
        "output_4 = \"/content/HG003_gatk_updated.vcf\"\n",
        "\n",
        "#update_filter_column(file_1, reference_vcf_path, output_1)\n",
        "update_filter_column(file_2, reference_vcf_path, output_2)\n",
        "update_filter_column(file_4, reference_vcf_path, output_4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVCzOI4uprsk"
      },
      "outputs": [],
      "source": [
        "cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vugLRvXN43nQ"
      },
      "outputs": [],
      "source": [
        "!apt-get install vcftools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WvM2CJT8Pbe"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8zjFC2_5R_S"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZuXkH0y3TKa"
      },
      "outputs": [],
      "source": [
        "#print the number of fail variants\n",
        "#!grep -o -i FAIL HG003_platypus_updated.vcf | wc -l\n",
        "!grep -o -i FAIL HG003_bcf_updated.vcf | wc -l\n",
        "!grep -o -i FAIL HG003_gatk_updated.vcf | wc -l\n",
        "\n",
        "#!grep -o -i PASS HG003_platypus_updated.vcf | wc -l\n",
        "!grep -o -i PASS HG003_bcf_updated.vcf | wc -l\n",
        "!grep -o -i PASS HG003_gatk_updated.vcf | wc -l\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0gdtBx64s2Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaUncurf43hW"
      },
      "outputs": [],
      "source": [
        "!ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs7n3cTS42fA"
      },
      "outputs": [],
      "source": [
        "!vcf-concat HG003_bcf_updated.vcf \\\n",
        "  HG003_gatk_updated.vcf > HG003_merged.vcf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6OWUMqlqvsd"
      },
      "outputs": [],
      "source": [
        "ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRmyUHNTt3ez"
      },
      "outputs": [],
      "source": [
        "!cat HG003_merged.vcf | vcf-annotate --fill-type | grep -oP \"TYPE=\\w+\" | sort | uniq -c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -o -i PASS HG003_merged.vcf | wc -l\n",
        "!grep -o -i FAIL HG003_merged.vcf | wc -l"
      ],
      "metadata": {
        "id": "kfkcPrPCW_c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InR0kuO3unaM"
      },
      "outputs": [],
      "source": [
        "#!vcftools --vcf HG003_merged.vcf --remove-indels --recode --recode-INFO-all --out SNPs_merged_hg003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JbfaJiSZCPv"
      },
      "outputs": [],
      "source": [
        "#!cat SNPs_merged_hg003.recode.vcf | vcf-annotate --fill-type | grep -oP \"TYPE=\\w+\" | sort | uniq -c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGjDREbjZCRu"
      },
      "outputs": [],
      "source": [
        "#!vcftools --vcf HG003_merged.vcf --keep-only-indels --recode --recode-INFO-all --out INDELs_merged_hg003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL6AXhGNepqS"
      },
      "outputs": [],
      "source": [
        "#!cat INDELs_merged_hg003.recode.vcf | vcf-annotate --fill-type | grep -oP \"TYPE=\\w+\" | sort | uniq -c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zrUTn1ffk_T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfEpl3ZeflEC"
      },
      "outputs": [],
      "source": [
        "#find unique words to be added later in the vocab list for the TRNASFORMERS model\n",
        "def find_words_between_substring(file_path):\n",
        "    found_words = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        start_index = content.find(\"ID=\")\n",
        "\n",
        "        while start_index != -1:\n",
        "            start_index += 3  # Length of \"ID=\"\n",
        "            end_index = content.find(\",\", start_index)\n",
        "            if end_index != -1:\n",
        "                found_words.append(content[start_index:end_index].strip())\n",
        "            start_index = content.find(\"ID=\", end_index)\n",
        "\n",
        "    return found_words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg06ss65flF4"
      },
      "outputs": [],
      "source": [
        "# Usage example\n",
        "file_path_1 = \"HG003_bcf_updated.vcf\"  # Replace with your file path\n",
        "#file_path_2 = \"HG003_platypus_updated.vcf\"\n",
        "file_path_3 = \"HG003_gatk_updated.vcf\"\n",
        "result_1 = find_words_between_substring(file_path_1)\n",
        "print(result_1)\n",
        "#result_2 = find_words_between_substring(file_path_2)\n",
        "#print(result_2)\n",
        "result_3 = find_words_between_substring(file_path_3)\n",
        "print(result_3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8W2UEDAKyYf"
      },
      "outputs": [],
      "source": [
        "#remove not needed words\n",
        "print(result_1.index('chr1'))\n",
        "print(result_3.index('chr1'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jKCjkfMPFb-"
      },
      "outputs": [],
      "source": [
        "result_1 = result_1[:21]\n",
        "result_3 = result_3[1:22]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVrm0i0m46SJ"
      },
      "outputs": [],
      "source": [
        "out_1 = map(lambda x:x.lower(), result_1)\n",
        "#out_2 = map(lambda x:x.lower(), result_2)\n",
        "out_3 = map(lambda x:x.lower(), result_3)\n",
        "\n",
        "\n",
        "result_1 = list(out_1)\n",
        "#result_2 = list(out_2)\n",
        "result_3 = list(out_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCQcEJ9kKyfg"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(result_1)\n",
        "#print(result_2)\n",
        "print(result_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miLwo1zHi8wx"
      },
      "outputs": [],
      "source": [
        "!head bert-base-uncased-vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l bert-base-uncased-vocab.txt"
      ],
      "metadata": {
        "id": "La4ZgqvNk5sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvzMsKNghqnr"
      },
      "outputs": [],
      "source": [
        "#add unique words to the bert_base_uncased vocabs\n",
        "with open(\"bert-base-uncased-vocab.txt\", \"a\") as f:\n",
        "   for word in result_1:\n",
        "     f.write(word+'\\n')\n",
        "   for z in result_3:\n",
        "     f.write(z+'\\n')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "584ZrJyJjswZ"
      },
      "outputs": [],
      "source": [
        "!wc -l bert-base-uncased-vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrtEy5SWjsyj"
      },
      "outputs": [],
      "source": [
        "def remove_duplicate_words(file_path, output_file_path):\n",
        "    unique_words = []\n",
        "    seen_words = set()\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            words = line.strip().split()\n",
        "            for word in words:\n",
        "                if word not in seen_words:\n",
        "                    unique_words.append(word)\n",
        "                    seen_words.add(word)\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        for word in unique_words:\n",
        "            output_file.write(word + '\\n')\n",
        "# Usage example\n",
        "input_file_path = \"bert-base-uncased-vocab.txt\"  # Replace with your input file path\n",
        "output_file_path = \"unique_word.txt\"  # Replace with your desired output file path\n",
        "remove_duplicate_words(input_file_path, output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28M-bEFePtzx"
      },
      "outputs": [],
      "source": [
        "!wc -l unique_word.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq2SHjcIkTao"
      },
      "outputs": [],
      "source": [
        "!tail -26 unique_word.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDfrvULP42hl",
        "outputId": "d2907c7a-1159-449d-86dd-88e42b848390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "awk: cannot open HG003_merged.vcf (No such file or directory)\n"
          ]
        }
      ],
      "source": [
        "#!awk '/^##/{h=$0; next} /^#CHROM/{print h; print; next} {print}' SNPs_merged_hg003.recode.vcf > hg003_snps.vcf\n",
        "#!awk '/^##/{h=$0; next} /^#CHROM/{print h; print; next} {print}' INDELs_merged_hg003.recode.vcf > hg003_indel.vcf\n",
        "!awk '/^##/{h=$0; next} /^#CHROM/{print h; print; next} {print}' HG003_merged.vcf > hg003_merged.vcf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS5vD9GgkkkL"
      },
      "outputs": [],
      "source": [
        "!head hg003_merged.vcf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrFF-TMrIWp-"
      },
      "outputs": [],
      "source": [
        "#!sed -i '1d' hg003_snps.vcf\n",
        "#!sed -i '1d' hg003_indel.vcf\n",
        "!sed -i '1d' hg003_merged.vcf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bNgE_2x42k_"
      },
      "outputs": [],
      "source": [
        "!head -15 hg003_merged.vcf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUOkW8Js3xdj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"hg003_merged.vcf\", delimiter='\\t', header=None, names=['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'HG003'], low_memory=False)\n",
        "\n",
        "\n",
        "df=df.drop(df.columns[[0, 1, 2, 3, 4]], axis=1)\n",
        "\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training lines: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "print(df.sample(3, random_state=42))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJYq9XYK3xf9"
      },
      "outputs": [],
      "source": [
        "df['FILTER'].replace(['PASS', 'FAIL'],\n",
        "                        [0, 1], inplace=True)\n",
        "\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRQxrpUx3xiP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HewiMdwo3xke"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbCLvS9R3xmt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNf0iYV13xo8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de0HNqvl3xrU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isaJMU8R3xtf"
      },
      "outputs": [],
      "source": [
        "df.to_csv('hg003_bcf_gatk.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzomDayW3xvh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiPyVvff3xxr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urYC2lSG3xzt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKQ-z8K6OV_Z"
      },
      "outputs": [],
      "source": [
        "!cp hg003_bcf_gatk.csv ./drive/MyDrive/Colab\\ Notebooks/deepref\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp unique_word.txt ./drive/MyDrive/Colab\\ Notebooks/deepref\n"
      ],
      "metadata": {
        "id": "iQHYujvvj74C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l unique_word.txt\n",
        "!wc -l bert-base-uncased-vocab.txt"
      ],
      "metadata": {
        "id": "zUSP1KO_kdD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NImLjgqlEZS9"
      },
      "outputs": [],
      "source": [
        "ls -lh ./drive/MyDrive/Colab\\ Notebooks/deepref"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hy4JKboEc9b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
