{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvttGs13FkA1"
      },
      "outputs": [],
      "source": [
        "!apt-get install pyvcf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDG3wFEmGbUH"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y tabix\n",
        "!pip install pytabix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!grep -o -i PASS HG003_GRCh38_1_22_v4.2.1_benchmark.vcf | wc -l\n",
        "!grep -o -i FAIL HG003_GRCh38_1_22_v4.2.1_benchmark.vcf | wc -l"
      ],
      "metadata": {
        "id": "N5OXup-rWZzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKxXK6wW7WHm"
      },
      "outputs": [],
      "source": [
        "import vcf\n",
        "\n",
        "#if a variat exist in both a VCF file anf the reference VCF, the variant FILTER is set to PASS. Else, it is FAIL\n",
        "def update_filter_column(vcf_file, reference_vcf, output_vcf):\n",
        "    vcf_reader = vcf.Reader(filename=vcf_file)\n",
        "    reference_reader = vcf.Reader(filename=reference_vcf)\n",
        "\n",
        "    reference_variants = set((record.POS) for record in reference_reader)\n",
        "\n",
        "    vcf_writer = vcf.Writer(open(output_vcf, 'w'), vcf_reader)\n",
        "\n",
        "    for record in vcf_reader:\n",
        "        variant_key = (record.POS)\n",
        "        if variant_key in reference_variants:\n",
        "            record.FILTER = \"PASS\"\n",
        "\n",
        "        else:\n",
        "            record.FILTER = \"FAIL\"\n",
        "\n",
        "        vcf_writer.write_record(record)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtGdqJyO7Rho"
      },
      "outputs": [],
      "source": [
        "# Provide the paths to your VCF files\n",
        "file_1 = \"HG003-bcf.vcf\"\n",
        "file_2 = \"HG003_gatk.vcf\"\n",
        "reference_vcf_path = \"HG003_GRCh38_1_22_v4.2.1_benchmark.vcf\"\n",
        "output_1 = \"/content/HG003_bcf_updated.vcf\"\n",
        "output_2 = \"/content/HG003_gatk_updated.vcf\"\n",
        "\n",
        "update_filter_column(file_1, reference_vcf_path, output_2)\n",
        "update_filter_column(file_2, reference_vcf_path, output_4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vugLRvXN43nQ"
      },
      "outputs": [],
      "source": [
        "!apt-get install vcftools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZuXkH0y3TKa"
      },
      "outputs": [],
      "source": [
        "#print the number of fail variants\n",
        "!grep -o -i FAIL HG003_bcf_updated.vcf | wc -l\n",
        "!grep -o -i FAIL HG003_gatk_updated.vcf | wc -l\n",
        "\n",
        "#print the number of pass variants\n",
        "!grep -o -i PASS HG003_bcf_updated.vcf | wc -l\n",
        "!grep -o -i PASS HG003_gatk_updated.vcf | wc -l\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaUncurf43hW"
      },
      "outputs": [],
      "source": [
        "!ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs7n3cTS42fA"
      },
      "outputs": [],
      "source": [
        "!vcf-concat HG003_bcf_updated.vcf \\\n",
        "  HG003_gatk_updated.vcf > HG003_merged.vcf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6OWUMqlqvsd"
      },
      "outputs": [],
      "source": [
        "ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRmyUHNTt3ez"
      },
      "outputs": [],
      "source": [
        "!cat HG003_merged.vcf | vcf-annotate --fill-type | grep -oP \"TYPE=\\w+\" | sort | uniq -c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -o -i PASS HG003_merged.vcf | wc -l\n",
        "!grep -o -i FAIL HG003_merged.vcf | wc -l"
      ],
      "metadata": {
        "id": "kfkcPrPCW_c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zrUTn1ffk_T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfEpl3ZeflEC"
      },
      "outputs": [],
      "source": [
        "#find unique words to be added later in the vocab list for the TRNASFORMERS model\n",
        "def find_words_between_substring(file_path):\n",
        "    found_words = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        start_index = content.find(\"ID=\")\n",
        "\n",
        "        while start_index != -1:\n",
        "            start_index += 3  # Length of \"ID=\"\n",
        "            end_index = content.find(\",\", start_index)\n",
        "            if end_index != -1:\n",
        "                found_words.append(content[start_index:end_index].strip())\n",
        "            start_index = content.find(\"ID=\", end_index)\n",
        "\n",
        "    return found_words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg06ss65flF4"
      },
      "outputs": [],
      "source": [
        "# Usage example\n",
        "file_path_1 = \"HG003_bcf_updated.vcf\"  # Replace with your file path\n",
        "file_path_2 = \"HG003_gatk_updated.vcf\"\n",
        "result_1 = find_words_between_substring(file_path_1)\n",
        "print(result_1)\n",
        "result_2 = find_words_between_substring(file_path_2)\n",
        "print(result_2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8W2UEDAKyYf"
      },
      "outputs": [],
      "source": [
        "#remove not needed words\n",
        "print(result_1.index('chr1'))\n",
        "print(result_2.index('chr1'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jKCjkfMPFb-"
      },
      "outputs": [],
      "source": [
        "result_1 = result_1[:21]\n",
        "result_2 = result_2[1:22]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVrm0i0m46SJ"
      },
      "outputs": [],
      "source": [
        "out_1 = map(lambda x:x.lower(), result_1)\n",
        "out_2 = map(lambda x:x.lower(), result_2)\n",
        "\n",
        "\n",
        "result_1 = list(out_1)\n",
        "result_2 = list(out_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCQcEJ9kKyfg"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(result_1)\n",
        "print(result_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miLwo1zHi8wx"
      },
      "outputs": [],
      "source": [
        "!head bert-base-uncased-vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l bert-base-uncased-vocab.txt"
      ],
      "metadata": {
        "id": "La4ZgqvNk5sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvzMsKNghqnr"
      },
      "outputs": [],
      "source": [
        "#add unique words to the bert_base_uncased vocabs\n",
        "with open(\"bert-base-uncased-vocab.txt\", \"a\") as f:\n",
        "   for word in result_1:\n",
        "     f.write(word+'\\n')\n",
        "   for z in result_2:\n",
        "     f.write(z+'\\n')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "584ZrJyJjswZ"
      },
      "outputs": [],
      "source": [
        "!wc -l bert-base-uncased-vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrtEy5SWjsyj"
      },
      "outputs": [],
      "source": [
        "def remove_duplicate_words(file_path, output_file_path):\n",
        "    unique_words = []\n",
        "    seen_words = set()\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            words = line.strip().split()\n",
        "            for word in words:\n",
        "                if word not in seen_words:\n",
        "                    unique_words.append(word)\n",
        "                    seen_words.add(word)\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        for word in unique_words:\n",
        "            output_file.write(word + '\\n')\n",
        "# Usage example\n",
        "input_file_path = \"bert-base-uncased-vocab.txt\"  # Replace with your input file path\n",
        "output_file_path = \"unique_word.txt\"  # Replace with your desired output file path\n",
        "remove_duplicate_words(input_file_path, output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28M-bEFePtzx"
      },
      "outputs": [],
      "source": [
        "!wc -l unique_word.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq2SHjcIkTao"
      },
      "outputs": [],
      "source": [
        "!tail -26 unique_word.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDfrvULP42hl"
      },
      "outputs": [],
      "source": [
        "\n",
        "!awk '/^##/{h=$0; next} /^#CHROM/{print h; print; next} {print}' HG003_merged.vcf > hg003_merged.vcf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS5vD9GgkkkL"
      },
      "outputs": [],
      "source": [
        "!head hg003_merged.vcf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrFF-TMrIWp-"
      },
      "outputs": [],
      "source": [
        "\n",
        "!sed -i '1d' hg003_merged.vcf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bNgE_2x42k_"
      },
      "outputs": [],
      "source": [
        "!head -15 hg003_merged.vcf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUOkW8Js3xdj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"hg003_merged.vcf\", delimiter='\\t', header=None, names=['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'HG003'], low_memory=False)\n",
        "\n",
        "\n",
        "df=df.drop(df.columns[[0, 1, 2, 3, 4]], axis=1)\n",
        "\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training lines: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "print(df.sample(3, random_state=42))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJYq9XYK3xf9"
      },
      "outputs": [],
      "source": [
        "df['FILTER'].replace(['PASS', 'FAIL'],\n",
        "                        [0, 1], inplace=True)\n",
        "\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isaJMU8R3xtf"
      },
      "outputs": [],
      "source": [
        "df.to_csv('hg003_bcf_gatk.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l unique_word.txt\n",
        "!wc -l bert-base-uncased-vocab.txt"
      ],
      "metadata": {
        "id": "zUSP1KO_kdD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NImLjgqlEZS9"
      },
      "outputs": [],
      "source": [
        "ls -lh ./drive/MyDrive/Colab\\ Notebooks/deepref"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hy4JKboEc9b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}